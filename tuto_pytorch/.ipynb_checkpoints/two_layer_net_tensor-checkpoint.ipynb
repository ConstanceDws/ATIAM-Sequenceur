{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Tensors\n",
    "----------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer and no biases, trained to\n",
    "predict y from x by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation uses PyTorch tensors to manually compute the forward pass,\n",
    "loss, and backward pass.\n",
    "\n",
    "A PyTorch Tensor is basically the same as a numpy array: it does not know\n",
    "anything about deep learning or computational graphs or gradients, and is just\n",
    "a generic n-dimensional array to be used for arbitrary numeric computation.\n",
    "\n",
    "The biggest difference between a numpy array and a PyTorch Tensor is that\n",
    "a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU,\n",
    "just cast the Tensor to a cuda datatype.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 29718010.0)\n",
      "(1, 23124498.0)\n",
      "(2, 21245900.0)\n",
      "(3, 20435218.0)\n",
      "(4, 18944624.0)\n",
      "(5, 16079093.0)\n",
      "(6, 12329544.0)\n",
      "(7, 8603896.0)\n",
      "(8, 5646710.0)\n",
      "(9, 3608432.25)\n",
      "(10, 2331985.25)\n",
      "(11, 1561815.25)\n",
      "(12, 1100489.375)\n",
      "(13, 817215.875)\n",
      "(14, 636013.125)\n",
      "(15, 513838.46875)\n",
      "(16, 426681.71875)\n",
      "(17, 361299.90625)\n",
      "(18, 310192.875)\n",
      "(19, 268970.96875)\n",
      "(20, 234962.828125)\n",
      "(21, 206435.296875)\n",
      "(22, 182203.375)\n",
      "(23, 161451.640625)\n",
      "(24, 143531.875)\n",
      "(25, 127973.7265625)\n",
      "(26, 114409.4921875)\n",
      "(27, 102548.5390625)\n",
      "(28, 92140.53125)\n",
      "(29, 82958.9609375)\n",
      "(30, 74836.40625)\n",
      "(31, 67632.25)\n",
      "(32, 61233.4296875)\n",
      "(33, 55534.00390625)\n",
      "(34, 50442.85546875)\n",
      "(35, 45885.89453125)\n",
      "(36, 41801.19921875)\n",
      "(37, 38132.88671875)\n",
      "(38, 34829.06640625)\n",
      "(39, 31848.9453125)\n",
      "(40, 29158.599609375)\n",
      "(41, 26724.734375)\n",
      "(42, 24518.154296875)\n",
      "(43, 22515.10546875)\n",
      "(44, 20694.56640625)\n",
      "(45, 19037.87890625)\n",
      "(46, 17528.892578125)\n",
      "(47, 16152.6640625)\n",
      "(48, 14895.916015625)\n",
      "(49, 13750.0185546875)\n",
      "(50, 12701.326171875)\n",
      "(51, 11740.4521484375)\n",
      "(52, 10859.2802734375)\n",
      "(53, 10050.572265625)\n",
      "(54, 9307.9375)\n",
      "(55, 8625.5498046875)\n",
      "(56, 7997.7919921875)\n",
      "(57, 7420.0546875)\n",
      "(58, 6887.6220703125)\n",
      "(59, 6396.87158203125)\n",
      "(60, 5944.39501953125)\n",
      "(61, 5526.68359375)\n",
      "(62, 5140.5810546875)\n",
      "(63, 4783.5341796875)\n",
      "(64, 4453.419921875)\n",
      "(65, 4148.37255859375)\n",
      "(66, 3866.05078125)\n",
      "(67, 3604.47802734375)\n",
      "(68, 3361.894775390625)\n",
      "(69, 3136.86669921875)\n",
      "(70, 2927.982177734375)\n",
      "(71, 2734.027099609375)\n",
      "(72, 2553.81396484375)\n",
      "(73, 2386.38525390625)\n",
      "(74, 2230.674560546875)\n",
      "(75, 2085.74267578125)\n",
      "(76, 1950.83984375)\n",
      "(77, 1825.2918701171875)\n",
      "(78, 1708.3245849609375)\n",
      "(79, 1599.4173583984375)\n",
      "(80, 1498.034423828125)\n",
      "(81, 1403.4949951171875)\n",
      "(82, 1315.30322265625)\n",
      "(83, 1233.02099609375)\n",
      "(84, 1156.18408203125)\n",
      "(85, 1084.4249267578125)\n",
      "(86, 1017.3746337890625)\n",
      "(87, 954.7105712890625)\n",
      "(88, 896.137451171875)\n",
      "(89, 841.37841796875)\n",
      "(90, 790.1385498046875)\n",
      "(91, 742.1996459960938)\n",
      "(92, 697.3535766601562)\n",
      "(93, 655.3444213867188)\n",
      "(94, 616.0208129882812)\n",
      "(95, 579.1641235351562)\n",
      "(96, 544.633056640625)\n",
      "(97, 512.28857421875)\n",
      "(98, 481.9599304199219)\n",
      "(99, 453.5166320800781)\n",
      "(100, 426.83837890625)\n",
      "(101, 401.80792236328125)\n",
      "(102, 378.3126220703125)\n",
      "(103, 356.26593017578125)\n",
      "(104, 335.56915283203125)\n",
      "(105, 316.12982177734375)\n",
      "(106, 297.86846923828125)\n",
      "(107, 280.7268371582031)\n",
      "(108, 264.6097717285156)\n",
      "(109, 249.45852661132812)\n",
      "(110, 235.21751403808594)\n",
      "(111, 221.8271026611328)\n",
      "(112, 209.23634338378906)\n",
      "(113, 197.3939208984375)\n",
      "(114, 186.2503204345703)\n",
      "(115, 175.76043701171875)\n",
      "(116, 165.8889617919922)\n",
      "(117, 156.59255981445312)\n",
      "(118, 147.84629821777344)\n",
      "(119, 139.6141357421875)\n",
      "(120, 131.8522491455078)\n",
      "(121, 124.53978729248047)\n",
      "(122, 117.65360260009766)\n",
      "(123, 111.16586303710938)\n",
      "(124, 105.04701232910156)\n",
      "(125, 99.27819061279297)\n",
      "(126, 93.83917999267578)\n",
      "(127, 88.71050262451172)\n",
      "(128, 83.8745346069336)\n",
      "(129, 79.31388092041016)\n",
      "(130, 75.00816345214844)\n",
      "(131, 70.94869232177734)\n",
      "(132, 67.11544799804688)\n",
      "(133, 63.49726104736328)\n",
      "(134, 60.080780029296875)\n",
      "(135, 56.85493850708008)\n",
      "(136, 53.80923843383789)\n",
      "(137, 50.93550109863281)\n",
      "(138, 48.21923828125)\n",
      "(139, 45.65290451049805)\n",
      "(140, 43.229122161865234)\n",
      "(141, 40.93782043457031)\n",
      "(142, 38.77267837524414)\n",
      "(143, 36.72563171386719)\n",
      "(144, 34.792274475097656)\n",
      "(145, 32.9639892578125)\n",
      "(146, 31.235916137695312)\n",
      "(147, 29.59886932373047)\n",
      "(148, 28.052200317382812)\n",
      "(149, 26.588024139404297)\n",
      "(150, 25.204675674438477)\n",
      "(151, 23.895456314086914)\n",
      "(152, 22.65788459777832)\n",
      "(153, 21.48741912841797)\n",
      "(154, 20.379152297973633)\n",
      "(155, 19.329021453857422)\n",
      "(156, 18.33528709411621)\n",
      "(157, 17.394681930541992)\n",
      "(158, 16.50339126586914)\n",
      "(159, 15.659034729003906)\n",
      "(160, 14.85925579071045)\n",
      "(161, 14.101943969726562)\n",
      "(162, 13.384557723999023)\n",
      "(163, 12.704648971557617)\n",
      "(164, 12.059975624084473)\n",
      "(165, 11.449548721313477)\n",
      "(166, 10.870816230773926)\n",
      "(167, 10.321605682373047)\n",
      "(168, 9.80212116241455)\n",
      "(169, 9.308600425720215)\n",
      "(170, 8.840970039367676)\n",
      "(171, 8.397499084472656)\n",
      "(172, 7.976853370666504)\n",
      "(173, 7.577800750732422)\n",
      "(174, 7.199385166168213)\n",
      "(175, 6.840219974517822)\n",
      "(176, 6.499795436859131)\n",
      "(177, 6.176731586456299)\n",
      "(178, 5.870133876800537)\n",
      "(179, 5.578813552856445)\n",
      "(180, 5.3027191162109375)\n",
      "(181, 5.040377140045166)\n",
      "(182, 4.791521072387695)\n",
      "(183, 4.555496692657471)\n",
      "(184, 4.330925464630127)\n",
      "(185, 4.118230819702148)\n",
      "(186, 3.9159579277038574)\n",
      "(187, 3.7238070964813232)\n",
      "(188, 3.541494131088257)\n",
      "(189, 3.368227481842041)\n",
      "(190, 3.2036452293395996)\n",
      "(191, 3.0476698875427246)\n",
      "(192, 2.8990912437438965)\n",
      "(193, 2.758002996444702)\n",
      "(194, 2.6240005493164062)\n",
      "(195, 2.4967799186706543)\n",
      "(196, 2.3754560947418213)\n",
      "(197, 2.2604618072509766)\n",
      "(198, 2.151127815246582)\n",
      "(199, 2.0474705696105957)\n",
      "(200, 1.9485819339752197)\n",
      "(201, 1.854657769203186)\n",
      "(202, 1.7653721570968628)\n",
      "(203, 1.6805979013442993)\n",
      "(204, 1.5999267101287842)\n",
      "(205, 1.5231499671936035)\n",
      "(206, 1.4500139951705933)\n",
      "(207, 1.3807387351989746)\n",
      "(208, 1.3147450685501099)\n",
      "(209, 1.2519676685333252)\n",
      "(210, 1.1921695470809937)\n",
      "(211, 1.135524034500122)\n",
      "(212, 1.081394076347351)\n",
      "(213, 1.0300709009170532)\n",
      "(214, 0.9810758829116821)\n",
      "(215, 0.9345702528953552)\n",
      "(216, 0.8903471827507019)\n",
      "(217, 0.8481639623641968)\n",
      "(218, 0.8080029487609863)\n",
      "(219, 0.7698650360107422)\n",
      "(220, 0.733479917049408)\n",
      "(221, 0.6988424062728882)\n",
      "(222, 0.6659485697746277)\n",
      "(223, 0.6346257925033569)\n",
      "(224, 0.6048102974891663)\n",
      "(225, 0.5763826966285706)\n",
      "(226, 0.5492652058601379)\n",
      "(227, 0.5235756039619446)\n",
      "(228, 0.4991028606891632)\n",
      "(229, 0.475681334733963)\n",
      "(230, 0.453484445810318)\n",
      "(231, 0.43228691816329956)\n",
      "(232, 0.412082701921463)\n",
      "(233, 0.392855167388916)\n",
      "(234, 0.37463173270225525)\n",
      "(235, 0.3571901023387909)\n",
      "(236, 0.34057360887527466)\n",
      "(237, 0.3247595727443695)\n",
      "(238, 0.3096626102924347)\n",
      "(239, 0.29534587264060974)\n",
      "(240, 0.2816704511642456)\n",
      "(241, 0.26857563853263855)\n",
      "(242, 0.256180077791214)\n",
      "(243, 0.24432989954948425)\n",
      "(244, 0.2330305576324463)\n",
      "(245, 0.22228221595287323)\n",
      "(246, 0.2120436578989029)\n",
      "(247, 0.20228801667690277)\n",
      "(248, 0.1929660439491272)\n",
      "(249, 0.18405301868915558)\n",
      "(250, 0.17557498812675476)\n",
      "(251, 0.16754354536533356)\n",
      "(252, 0.1598726511001587)\n",
      "(253, 0.15252618491649628)\n",
      "(254, 0.14557594060897827)\n",
      "(255, 0.1388690024614334)\n",
      "(256, 0.13252197206020355)\n",
      "(257, 0.12647801637649536)\n",
      "(258, 0.12066788226366043)\n",
      "(259, 0.11516769975423813)\n",
      "(260, 0.10990117490291595)\n",
      "(261, 0.10491039603948593)\n",
      "(262, 0.10011430084705353)\n",
      "(263, 0.09556606411933899)\n",
      "(264, 0.09121916443109512)\n",
      "(265, 0.08704683184623718)\n",
      "(266, 0.08311442285776138)\n",
      "(267, 0.07934587448835373)\n",
      "(268, 0.07575181126594543)\n",
      "(269, 0.07230745255947113)\n",
      "(270, 0.0690511092543602)\n",
      "(271, 0.06590717285871506)\n",
      "(272, 0.06294326484203339)\n",
      "(273, 0.06009320169687271)\n",
      "(274, 0.05736895278096199)\n",
      "(275, 0.05480765178799629)\n",
      "(276, 0.052309442311525345)\n",
      "(277, 0.04999225214123726)\n",
      "(278, 0.0477188378572464)\n",
      "(279, 0.045560114085674286)\n",
      "(280, 0.043517034500837326)\n",
      "(281, 0.04157451167702675)\n",
      "(282, 0.03971750661730766)\n",
      "(283, 0.037940386682748795)\n",
      "(284, 0.03623633831739426)\n",
      "(285, 0.0346124991774559)\n",
      "(286, 0.03306780382990837)\n",
      "(287, 0.03160592541098595)\n",
      "(288, 0.03018089383840561)\n",
      "(289, 0.028853273019194603)\n",
      "(290, 0.027545997872948647)\n",
      "(291, 0.026333162561058998)\n",
      "(292, 0.02517164684832096)\n",
      "(293, 0.02404068224132061)\n",
      "(294, 0.022973740473389626)\n",
      "(295, 0.02194799855351448)\n",
      "(296, 0.02096369117498398)\n",
      "(297, 0.020043982192873955)\n",
      "(298, 0.019171778112649918)\n",
      "(299, 0.018329210579395294)\n",
      "(300, 0.01752079650759697)\n",
      "(301, 0.016751648858189583)\n",
      "(302, 0.01600952260196209)\n",
      "(303, 0.015306376852095127)\n",
      "(304, 0.014627069234848022)\n",
      "(305, 0.013992317020893097)\n",
      "(306, 0.013388773426413536)\n",
      "(307, 0.012808311730623245)\n",
      "(308, 0.012240319512784481)\n",
      "(309, 0.011711210943758488)\n",
      "(310, 0.011212384328246117)\n",
      "(311, 0.010711897164583206)\n",
      "(312, 0.010256300680339336)\n",
      "(313, 0.009812821634113789)\n",
      "(314, 0.009391936473548412)\n",
      "(315, 0.008985948748886585)\n",
      "(316, 0.008606796152889729)\n",
      "(317, 0.008238043636083603)\n",
      "(318, 0.007890268228948116)\n",
      "(319, 0.0075559900142252445)\n",
      "(320, 0.007228792645037174)\n",
      "(321, 0.006921230815351009)\n",
      "(322, 0.0066299219615757465)\n",
      "(323, 0.006349131930619478)\n",
      "(324, 0.0060836635529994965)\n",
      "(325, 0.00582517497241497)\n",
      "(326, 0.005582913756370544)\n",
      "(327, 0.005344693548977375)\n",
      "(328, 0.00512349558994174)\n",
      "(329, 0.004909434821456671)\n",
      "(330, 0.004710096400231123)\n",
      "(331, 0.004514916799962521)\n",
      "(332, 0.0043303887359797955)\n",
      "(333, 0.0041487496346235275)\n",
      "(334, 0.003977075219154358)\n",
      "(335, 0.003817701479420066)\n",
      "(336, 0.0036635177675634623)\n",
      "(337, 0.0035134435165673494)\n",
      "(338, 0.003371222410351038)\n",
      "(339, 0.003239137353375554)\n",
      "(340, 0.0031104213558137417)\n",
      "(341, 0.002986846026033163)\n",
      "(342, 0.002871258184313774)\n",
      "(343, 0.002757512964308262)\n",
      "(344, 0.002649245783686638)\n",
      "(345, 0.002546910895034671)\n",
      "(346, 0.002449700841680169)\n",
      "(347, 0.0023567304015159607)\n",
      "(348, 0.0022659802343696356)\n",
      "(349, 0.002176114125177264)\n",
      "(350, 0.0020949586760252714)\n",
      "(351, 0.002017316408455372)\n",
      "(352, 0.0019428023369982839)\n",
      "(353, 0.0018700798973441124)\n",
      "(354, 0.001800204161554575)\n",
      "(355, 0.0017356127500534058)\n",
      "(356, 0.0016729291528463364)\n",
      "(357, 0.0016127489507198334)\n",
      "(358, 0.001554036163724959)\n",
      "(359, 0.0014979935949668288)\n",
      "(360, 0.0014433880569413304)\n",
      "(361, 0.0013913741568103433)\n",
      "(362, 0.001343267154879868)\n",
      "(363, 0.0012974836863577366)\n",
      "(364, 0.001249742810614407)\n",
      "(365, 0.0012081424938514829)\n",
      "(366, 0.0011657606810331345)\n",
      "(367, 0.0011260532774031162)\n",
      "(368, 0.0010906208772212267)\n",
      "(369, 0.0010515045141801238)\n",
      "(370, 0.001016599009744823)\n",
      "(371, 0.0009814451914280653)\n",
      "(372, 0.0009490751544944942)\n",
      "(373, 0.000918503210414201)\n",
      "(374, 0.0008875906351022422)\n",
      "(375, 0.0008584998431615531)\n",
      "(376, 0.0008310278644785285)\n",
      "(377, 0.0008039483800530434)\n",
      "(378, 0.0007787665817886591)\n",
      "(379, 0.0007538550416938961)\n",
      "(380, 0.0007300152792595327)\n",
      "(381, 0.0007069639395922422)\n",
      "(382, 0.00068559410283342)\n",
      "(383, 0.0006631760625168681)\n",
      "(384, 0.0006433945382013917)\n",
      "(385, 0.0006245601689442992)\n",
      "(386, 0.0006072570686228573)\n",
      "(387, 0.0005887158331461251)\n",
      "(388, 0.0005723883514292538)\n",
      "(389, 0.0005553190712817013)\n",
      "(390, 0.000537988671567291)\n",
      "(391, 0.0005229610833339393)\n",
      "(392, 0.0005082915886305273)\n",
      "(393, 0.0004946214612573385)\n",
      "(394, 0.000478929141536355)\n",
      "(395, 0.00046634592581540346)\n",
      "(396, 0.0004531382001005113)\n",
      "(397, 0.0004404184583108872)\n",
      "(398, 0.00042829461744986475)\n",
      "(399, 0.00041689834324643016)\n",
      "(400, 0.00040486344369128346)\n",
      "(401, 0.00039399106753990054)\n",
      "(402, 0.0003845211467705667)\n",
      "(403, 0.0003746202273759991)\n",
      "(404, 0.00036489267949946225)\n",
      "(405, 0.00035474204923957586)\n",
      "(406, 0.00034624949330464005)\n",
      "(407, 0.0003372466017026454)\n",
      "(408, 0.00032851245487108827)\n",
      "(409, 0.00032019513309933245)\n",
      "(410, 0.0003121693152934313)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 0.0003046701895073056)\n",
      "(412, 0.0002964297018479556)\n",
      "(413, 0.0002896718215197325)\n",
      "(414, 0.00028256591758690774)\n",
      "(415, 0.0002763792290352285)\n",
      "(416, 0.0002702175115700811)\n",
      "(417, 0.00026265886845067143)\n",
      "(418, 0.0002572580415289849)\n",
      "(419, 0.00025102810468524694)\n",
      "(420, 0.0002448788727633655)\n",
      "(421, 0.00023956134100444615)\n",
      "(422, 0.00023397729091811925)\n",
      "(423, 0.00022859744785819203)\n",
      "(424, 0.00022345957404468209)\n",
      "(425, 0.00021863482834305614)\n",
      "(426, 0.00021413002104964107)\n",
      "(427, 0.00020906623103655875)\n",
      "(428, 0.00020428132847882807)\n",
      "(429, 0.00019950440037064254)\n",
      "(430, 0.00019547883130144328)\n",
      "(431, 0.00019182401592843235)\n",
      "(432, 0.0001870947307907045)\n",
      "(433, 0.000182921823579818)\n",
      "(434, 0.00017894267512019724)\n",
      "(435, 0.000174925837200135)\n",
      "(436, 0.00017209304496645927)\n",
      "(437, 0.00016796549607533962)\n",
      "(438, 0.0001653602230362594)\n",
      "(439, 0.00016160414088517427)\n",
      "(440, 0.00015785083814989775)\n",
      "(441, 0.000154903216753155)\n",
      "(442, 0.00015163284842856228)\n",
      "(443, 0.0001487803820054978)\n",
      "(444, 0.00014550618652720004)\n",
      "(445, 0.00014284421922639012)\n",
      "(446, 0.00014016708882991225)\n",
      "(447, 0.000137139402795583)\n",
      "(448, 0.00013508679694496095)\n",
      "(449, 0.00013239550753496587)\n",
      "(450, 0.00012988888192921877)\n",
      "(451, 0.00012737532961182296)\n",
      "(452, 0.00012471659283619374)\n",
      "(453, 0.00012262995005585253)\n",
      "(454, 0.00012060330482199788)\n",
      "(455, 0.00011849149450426921)\n",
      "(456, 0.0001162940970971249)\n",
      "(457, 0.00011420653754612431)\n",
      "(458, 0.00011220075975870714)\n",
      "(459, 0.0001102657915907912)\n",
      "(460, 0.00010802409815369174)\n",
      "(461, 0.00010644696885719895)\n",
      "(462, 0.00010445906082168221)\n",
      "(463, 0.00010219927207799628)\n",
      "(464, 0.00010083404049510136)\n",
      "(465, 9.922064054990187e-05)\n",
      "(466, 9.716872591525316e-05)\n",
      "(467, 9.582562051946297e-05)\n",
      "(468, 9.429852070752531e-05)\n",
      "(469, 9.298561053583398e-05)\n",
      "(470, 9.176134335575625e-05)\n",
      "(471, 9.032025263877586e-05)\n",
      "(472, 8.855029591359198e-05)\n",
      "(473, 8.728379179956391e-05)\n",
      "(474, 8.561883441871032e-05)\n",
      "(475, 8.42414956423454e-05)\n",
      "(476, 8.281433110823855e-05)\n",
      "(477, 8.180744043784216e-05)\n",
      "(478, 8.064959547482431e-05)\n",
      "(479, 7.944199023768306e-05)\n",
      "(480, 7.836933218641207e-05)\n",
      "(481, 7.720076246187091e-05)\n",
      "(482, 7.63038988225162e-05)\n",
      "(483, 7.462432404281572e-05)\n",
      "(484, 7.346864731516689e-05)\n",
      "(485, 7.265844760695472e-05)\n",
      "(486, 7.161613757489249e-05)\n",
      "(487, 7.055883907014504e-05)\n",
      "(488, 6.932511314516887e-05)\n",
      "(489, 6.839141860837117e-05)\n",
      "(490, 6.771974585717544e-05)\n",
      "(491, 6.668400601483881e-05)\n",
      "(492, 6.571355334017426e-05)\n",
      "(493, 6.482213211711496e-05)\n",
      "(494, 6.387355824699625e-05)\n",
      "(495, 6.297439540503547e-05)\n",
      "(496, 6.215024768607691e-05)\n",
      "(497, 6.133349961601198e-05)\n",
      "(498, 6.0482925618998706e-05)\n",
      "(499, 5.93629629292991e-05)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
