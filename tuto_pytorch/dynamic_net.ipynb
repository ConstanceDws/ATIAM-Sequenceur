{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Control Flow + Weight Sharing\n",
    "--------------------------------------\n",
    "\n",
    "To showcase the power of PyTorch dynamic graphs, we will implement a very strange\n",
    "model: a fully-connected ReLU network that on each forward pass randomly chooses\n",
    "a number between 1 and 4 and has that many hidden layers, reusing the same\n",
    "weights multiple times to compute the innermost hidden layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 689.7920532226562)\n",
      "(1, 684.3121337890625)\n",
      "(2, 673.4315795898438)\n",
      "(3, 682.7122802734375)\n",
      "(4, 732.1351318359375)\n",
      "(5, 638.2893676757812)\n",
      "(6, 683.0774536132812)\n",
      "(7, 678.3356323242188)\n",
      "(8, 677.3494262695312)\n",
      "(9, 676.2898559570312)\n",
      "(10, 594.4865112304688)\n",
      "(11, 677.0089111328125)\n",
      "(12, 575.21533203125)\n",
      "(13, 561.4002685546875)\n",
      "(14, 543.1410522460938)\n",
      "(15, 670.1819458007812)\n",
      "(16, 668.3523559570312)\n",
      "(17, 665.7644653320312)\n",
      "(18, 474.66156005859375)\n",
      "(19, 449.76434326171875)\n",
      "(20, 654.01904296875)\n",
      "(21, 384.1488037109375)\n",
      "(22, 631.8275146484375)\n",
      "(23, 616.6630859375)\n",
      "(24, 350.31683349609375)\n",
      "(25, 239.10899353027344)\n",
      "(26, 544.433349609375)\n",
      "(27, 511.49017333984375)\n",
      "(28, 472.0292663574219)\n",
      "(29, 430.403564453125)\n",
      "(30, 469.1202697753906)\n",
      "(31, 370.1134033203125)\n",
      "(32, 409.05718994140625)\n",
      "(33, 389.7032775878906)\n",
      "(34, 376.1174011230469)\n",
      "(35, 318.2449035644531)\n",
      "(36, 215.1971435546875)\n",
      "(37, 189.6103515625)\n",
      "(38, 316.3470153808594)\n",
      "(39, 215.4353485107422)\n",
      "(40, 285.6966552734375)\n",
      "(41, 204.41908264160156)\n",
      "(42, 131.61582946777344)\n",
      "(43, 142.81532287597656)\n",
      "(44, 126.50502014160156)\n",
      "(45, 111.8926010131836)\n",
      "(46, 99.91449737548828)\n",
      "(47, 127.41578674316406)\n",
      "(48, 72.03323364257812)\n",
      "(49, 177.22927856445312)\n",
      "(50, 134.81935119628906)\n",
      "(51, 92.48978424072266)\n",
      "(52, 112.57380676269531)\n",
      "(53, 74.59950256347656)\n",
      "(54, 65.57779693603516)\n",
      "(55, 89.09203338623047)\n",
      "(56, 56.596595764160156)\n",
      "(57, 76.94668579101562)\n",
      "(58, 56.358726501464844)\n",
      "(59, 55.23047637939453)\n",
      "(60, 44.80183792114258)\n",
      "(61, 139.27955627441406)\n",
      "(62, 29.206928253173828)\n",
      "(63, 63.64912414550781)\n",
      "(64, 75.91496276855469)\n",
      "(65, 23.505701065063477)\n",
      "(66, 41.261932373046875)\n",
      "(67, 19.753843307495117)\n",
      "(68, 22.836833953857422)\n",
      "(69, 126.07003784179688)\n",
      "(70, 63.63758850097656)\n",
      "(71, 75.38314819335938)\n",
      "(72, 17.60237693786621)\n",
      "(73, 84.35868835449219)\n",
      "(74, 47.79668045043945)\n",
      "(75, 26.157245635986328)\n",
      "(76, 45.19723892211914)\n",
      "(77, 52.977664947509766)\n",
      "(78, 37.94342803955078)\n",
      "(79, 19.998023986816406)\n",
      "(80, 11.695653915405273)\n",
      "(81, 49.07772445678711)\n",
      "(82, 62.54762268066406)\n",
      "(83, 76.19133758544922)\n",
      "(84, 45.06044387817383)\n",
      "(85, 44.5544548034668)\n",
      "(86, 84.62696838378906)\n",
      "(87, 54.10215377807617)\n",
      "(88, 23.356107711791992)\n",
      "(89, 31.36294174194336)\n",
      "(90, 39.68424606323242)\n",
      "(91, 48.342933654785156)\n",
      "(92, 89.42130279541016)\n",
      "(93, 17.339351654052734)\n",
      "(94, 30.2364444732666)\n",
      "(95, 52.897438049316406)\n",
      "(96, 43.067569732666016)\n",
      "(97, 77.39762115478516)\n",
      "(98, 18.82955551147461)\n",
      "(99, 40.030601501464844)\n",
      "(100, 21.24693489074707)\n",
      "(101, 41.20024871826172)\n",
      "(102, 13.627906799316406)\n",
      "(103, 8.020298957824707)\n",
      "(104, 95.02328491210938)\n",
      "(105, 19.736318588256836)\n",
      "(106, 30.54055404663086)\n",
      "(107, 160.78836059570312)\n",
      "(108, 13.911335945129395)\n",
      "(109, 11.444555282592773)\n",
      "(110, 60.75259780883789)\n",
      "(111, 109.42838287353516)\n",
      "(112, 32.70781707763672)\n",
      "(113, 44.99908447265625)\n",
      "(114, 49.69429397583008)\n",
      "(115, 28.099973678588867)\n",
      "(116, 23.27553939819336)\n",
      "(117, 83.64225006103516)\n",
      "(118, 23.95330047607422)\n",
      "(119, 42.105831146240234)\n",
      "(120, 17.720489501953125)\n",
      "(121, 26.247488021850586)\n",
      "(122, 58.472530364990234)\n",
      "(123, 23.98542594909668)\n",
      "(124, 40.97435760498047)\n",
      "(125, 34.0162239074707)\n",
      "(126, 25.391199111938477)\n",
      "(127, 9.17101764678955)\n",
      "(128, 9.049424171447754)\n",
      "(129, 49.884918212890625)\n",
      "(130, 5.483603477478027)\n",
      "(131, 43.77952194213867)\n",
      "(132, 20.96952247619629)\n",
      "(133, 34.58774948120117)\n",
      "(134, 19.618907928466797)\n",
      "(135, 40.89466857910156)\n",
      "(136, 34.59202575683594)\n",
      "(137, 17.8432674407959)\n",
      "(138, 25.733774185180664)\n",
      "(139, 51.15665817260742)\n",
      "(140, 35.0250358581543)\n",
      "(141, 16.078819274902344)\n",
      "(142, 18.748918533325195)\n",
      "(143, 10.351177215576172)\n",
      "(144, 16.27179527282715)\n",
      "(145, 17.713163375854492)\n",
      "(146, 35.84052276611328)\n",
      "(147, 16.355806350708008)\n",
      "(148, 6.6543073654174805)\n",
      "(149, 13.68405532836914)\n",
      "(150, 27.77569580078125)\n",
      "(151, 11.625248908996582)\n",
      "(152, 5.931200981140137)\n",
      "(153, 9.998640060424805)\n",
      "(154, 16.14790916442871)\n",
      "(155, 10.100346565246582)\n",
      "(156, 16.026065826416016)\n",
      "(157, 12.350135803222656)\n",
      "(158, 10.981402397155762)\n",
      "(159, 7.1966447830200195)\n",
      "(160, 4.64893102645874)\n",
      "(161, 3.748817205429077)\n",
      "(162, 4.164120197296143)\n",
      "(163, 5.314709186553955)\n",
      "(164, 21.40545654296875)\n",
      "(165, 27.482465744018555)\n",
      "(166, 5.636025905609131)\n",
      "(167, 7.347306251525879)\n",
      "(168, 32.58592224121094)\n",
      "(169, 25.720605850219727)\n",
      "(170, 7.553707599639893)\n",
      "(171, 8.019750595092773)\n",
      "(172, 22.178314208984375)\n",
      "(173, 11.122437477111816)\n",
      "(174, 13.740070343017578)\n",
      "(175, 9.507007598876953)\n",
      "(176, 6.391271114349365)\n",
      "(177, 54.851043701171875)\n",
      "(178, 6.134705066680908)\n",
      "(179, 7.651916980743408)\n",
      "(180, 31.61678123474121)\n",
      "(181, 7.299853324890137)\n",
      "(182, 10.84875202178955)\n",
      "(183, 3.3886654376983643)\n",
      "(184, 8.571730613708496)\n",
      "(185, 3.8874707221984863)\n",
      "(186, 20.382036209106445)\n",
      "(187, 6.388951301574707)\n",
      "(188, 6.388842582702637)\n",
      "(189, 12.510674476623535)\n",
      "(190, 2.735023021697998)\n",
      "(191, 9.644048690795898)\n",
      "(192, 3.907613754272461)\n",
      "(193, 4.9784650802612305)\n",
      "(194, 4.817979335784912)\n",
      "(195, 1.1668179035186768)\n",
      "(196, 9.007305145263672)\n",
      "(197, 1.4842073917388916)\n",
      "(198, 3.906776189804077)\n",
      "(199, 1.8499959707260132)\n",
      "(200, 4.617587566375732)\n",
      "(201, 3.548628807067871)\n",
      "(202, 0.8531697988510132)\n",
      "(203, 8.452019691467285)\n",
      "(204, 2.652414560317993)\n",
      "(205, 5.022509574890137)\n",
      "(206, 4.048996448516846)\n",
      "(207, 4.6508941650390625)\n",
      "(208, 2.8858299255371094)\n",
      "(209, 3.5065934658050537)\n",
      "(210, 1.5098152160644531)\n",
      "(211, 4.163365840911865)\n",
      "(212, 4.434844970703125)\n",
      "(213, 1.9906216859817505)\n",
      "(214, 1.3702151775360107)\n",
      "(215, 0.8762858510017395)\n",
      "(216, 2.9907844066619873)\n",
      "(217, 19.27727508544922)\n",
      "(218, 1.1263442039489746)\n",
      "(219, 4.2343549728393555)\n",
      "(220, 8.019566535949707)\n",
      "(221, 2.9866952896118164)\n",
      "(222, 8.092948913574219)\n",
      "(223, 1.0084679126739502)\n",
      "(224, 4.037224292755127)\n",
      "(225, 1.9122015237808228)\n",
      "(226, 2.0497210025787354)\n",
      "(227, 4.885929107666016)\n",
      "(228, 10.341023445129395)\n",
      "(229, 1.0271611213684082)\n",
      "(230, 3.7510695457458496)\n",
      "(231, 13.968594551086426)\n",
      "(232, 4.824217319488525)\n",
      "(233, 3.57606840133667)\n",
      "(234, 1.5154387950897217)\n",
      "(235, 2.4983062744140625)\n",
      "(236, 0.45971477031707764)\n",
      "(237, 0.5272519588470459)\n",
      "(238, 0.4795171618461609)\n",
      "(239, 40.38138961791992)\n",
      "(240, 2.2600693702697754)\n",
      "(241, 9.818425178527832)\n",
      "(242, 16.291358947753906)\n",
      "(243, 21.347150802612305)\n",
      "(244, 5.32612943649292)\n",
      "(245, 1.9612581729888916)\n",
      "(246, 0.7767760157585144)\n",
      "(247, 1.8361200094223022)\n",
      "(248, 92.84300994873047)\n",
      "(249, 1.2130661010742188)\n",
      "(250, 17.016237258911133)\n",
      "(251, 8.436257362365723)\n",
      "(252, 12.424723625183105)\n",
      "(253, 58.468692779541016)\n",
      "(254, 5.788416385650635)\n",
      "(255, 0.9228523969650269)\n",
      "(256, 2.2946856021881104)\n",
      "(257, 26.512990951538086)\n",
      "(258, 16.211572647094727)\n",
      "(259, 11.468192100524902)\n",
      "(260, 9.151270866394043)\n",
      "(261, 4.8556413650512695)\n",
      "(262, 4.378395080566406)\n",
      "(263, 5.738420486450195)\n",
      "(264, 5.254052639007568)\n",
      "(265, 21.535547256469727)\n",
      "(266, 2.650988817214966)\n",
      "(267, 6.355311870574951)\n",
      "(268, 8.63236141204834)\n",
      "(269, 7.600340366363525)\n",
      "(270, 22.039831161499023)\n",
      "(271, 18.704792022705078)\n",
      "(272, 7.91281795501709)\n",
      "(273, 2.9400925636291504)\n",
      "(274, 1.800933599472046)\n",
      "(275, 1.861932635307312)\n",
      "(276, 10.872930526733398)\n",
      "(277, 28.634958267211914)\n",
      "(278, 2.3940272331237793)\n",
      "(279, 1.924684762954712)\n",
      "(280, 9.17572021484375)\n",
      "(281, 3.836613655090332)\n",
      "(282, 8.31498908996582)\n",
      "(283, 9.431605339050293)\n",
      "(284, 7.045760631561279)\n",
      "(285, 3.475872755050659)\n",
      "(286, 2.7978999614715576)\n",
      "(287, 1.4004535675048828)\n",
      "(288, 25.39267349243164)\n",
      "(289, 7.993177890777588)\n",
      "(290, 4.329105377197266)\n",
      "(291, 4.125258445739746)\n",
      "(292, 3.612311601638794)\n",
      "(293, 3.8196334838867188)\n",
      "(294, 3.91646671295166)\n",
      "(295, 3.645206928253174)\n",
      "(296, 24.904098510742188)\n",
      "(297, 3.5047929286956787)\n",
      "(298, 2.7946012020111084)\n",
      "(299, 7.3578290939331055)\n",
      "(300, 10.181269645690918)\n",
      "(301, 8.536619186401367)\n",
      "(302, 2.1026077270507812)\n",
      "(303, 1.9576964378356934)\n",
      "(304, 1.5845887660980225)\n",
      "(305, 5.952549934387207)\n",
      "(306, 12.522891998291016)\n",
      "(307, 5.842990875244141)\n",
      "(308, 1.382479190826416)\n",
      "(309, 1.443605661392212)\n",
      "(310, 18.221792221069336)\n",
      "(311, 0.8270109295845032)\n",
      "(312, 11.545136451721191)\n",
      "(313, 2.0299785137176514)\n",
      "(314, 2.132615089416504)\n",
      "(315, 4.567561626434326)\n",
      "(316, 7.298619270324707)\n",
      "(317, 5.782520294189453)\n",
      "(318, 2.476860523223877)\n",
      "(319, 0.654994785785675)\n",
      "(320, 3.8909895420074463)\n",
      "(321, 2.465780258178711)\n",
      "(322, 5.533722877502441)\n",
      "(323, 3.990389108657837)\n",
      "(324, 1.5057926177978516)\n",
      "(325, 1.80362069606781)\n",
      "(326, 1.2578891515731812)\n",
      "(327, 17.97034454345703)\n",
      "(328, 9.854229927062988)\n",
      "(329, 2.687920093536377)\n",
      "(330, 4.243598461151123)\n",
      "(331, 8.34976577758789)\n",
      "(332, 8.047952651977539)\n",
      "(333, 0.6631345748901367)\n",
      "(334, 1.0516756772994995)\n",
      "(335, 1.50071120262146)\n",
      "(336, 1.5676723718643188)\n",
      "(337, 1.6236872673034668)\n",
      "(338, 1.800869107246399)\n",
      "(339, 1.01370370388031)\n",
      "(340, 1.4524329900741577)\n",
      "(341, 2.4726595878601074)\n",
      "(342, 1.184210181236267)\n",
      "(343, 2.018191337585449)\n",
      "(344, 2.504209041595459)\n",
      "(345, 1.4769946336746216)\n",
      "(346, 5.379302024841309)\n",
      "(347, 3.305604934692383)\n",
      "(348, 0.813461184501648)\n",
      "(349, 4.043441295623779)\n",
      "(350, 1.5961103439331055)\n",
      "(351, 1.0948939323425293)\n",
      "(352, 2.1397721767425537)\n",
      "(353, 1.7633452415466309)\n",
      "(354, 2.071035623550415)\n",
      "(355, 1.7175499200820923)\n",
      "(356, 1.443516731262207)\n",
      "(357, 2.3438355922698975)\n",
      "(358, 1.4869869947433472)\n",
      "(359, 1.931780457496643)\n",
      "(360, 1.462384819984436)\n",
      "(361, 2.6283135414123535)\n",
      "(362, 3.444622755050659)\n",
      "(363, 0.9899493455886841)\n",
      "(364, 2.5017247200012207)\n",
      "(365, 3.6276490688323975)\n",
      "(366, 0.7732964158058167)\n",
      "(367, 0.5228247046470642)\n",
      "(368, 1.4876257181167603)\n",
      "(369, 0.5750107765197754)\n",
      "(370, 2.762094736099243)\n",
      "(371, 1.6019446849822998)\n",
      "(372, 1.0898691415786743)\n",
      "(373, 1.7420176267623901)\n",
      "(374, 1.5960407257080078)\n",
      "(375, 1.215652585029602)\n",
      "(376, 0.9445750713348389)\n",
      "(377, 0.7926982641220093)\n",
      "(378, 0.7714276313781738)\n",
      "(379, 1.556546688079834)\n",
      "(380, 1.8902416229248047)\n",
      "(381, 0.4256162643432617)\n",
      "(382, 1.5125610828399658)\n",
      "(383, 2.0007483959198)\n",
      "(384, 0.849348247051239)\n",
      "(385, 2.449604034423828)\n",
      "(386, 1.518349051475525)\n",
      "(387, 0.48447176814079285)\n",
      "(388, 0.39751455187797546)\n",
      "(389, 3.2577147483825684)\n",
      "(390, 1.3315589427947998)\n",
      "(391, 0.8785155415534973)\n",
      "(392, 1.0780980587005615)\n",
      "(393, 1.233557939529419)\n",
      "(394, 0.9057973027229309)\n",
      "(395, 0.6682270765304565)\n",
      "(396, 0.9743411540985107)\n",
      "(397, 1.4481395483016968)\n",
      "(398, 0.9742846488952637)\n",
      "(399, 0.9188419580459595)\n",
      "(400, 0.9399781227111816)\n",
      "(401, 0.46347472071647644)\n",
      "(402, 0.9915268421173096)\n",
      "(403, 1.4095396995544434)\n",
      "(404, 0.309821218252182)\n",
      "(405, 0.5177479386329651)\n",
      "(406, 1.196199655532837)\n",
      "(407, 1.0645835399627686)\n",
      "(408, 0.4981266260147095)\n",
      "(409, 0.4814804196357727)\n",
      "(410, 0.5183415412902832)\n",
      "(411, 1.0226612091064453)\n",
      "(412, 0.3068978786468506)\n",
      "(413, 0.28680655360221863)\n",
      "(414, 0.6218789219856262)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 0.15116798877716064)\n",
      "(416, 0.552038311958313)\n",
      "(417, 0.7097259163856506)\n",
      "(418, 0.10427719354629517)\n",
      "(419, 0.3098117709159851)\n",
      "(420, 0.16978657245635986)\n",
      "(421, 1.1964861154556274)\n",
      "(422, 0.24195222556591034)\n",
      "(423, 0.8830258846282959)\n",
      "(424, 0.6084325909614563)\n",
      "(425, 0.5918800234794617)\n",
      "(426, 0.9229487180709839)\n",
      "(427, 0.7504206299781799)\n",
      "(428, 0.4529557526111603)\n",
      "(429, 0.13673575222492218)\n",
      "(430, 0.5346847176551819)\n",
      "(431, 0.14599613845348358)\n",
      "(432, 0.4666462540626526)\n",
      "(433, 0.3772630989551544)\n",
      "(434, 0.15091900527477264)\n",
      "(435, 0.2660301625728607)\n",
      "(436, 0.24755322933197021)\n",
      "(437, 0.756074845790863)\n",
      "(438, 0.3098284602165222)\n",
      "(439, 0.9939972758293152)\n",
      "(440, 0.5796231627464294)\n",
      "(441, 0.2565430700778961)\n",
      "(442, 0.805530309677124)\n",
      "(443, 0.4702143967151642)\n",
      "(444, 0.126745343208313)\n",
      "(445, 0.3743031919002533)\n",
      "(446, 0.7716103196144104)\n",
      "(447, 0.7008016109466553)\n",
      "(448, 0.14494115114212036)\n",
      "(449, 0.41058897972106934)\n",
      "(450, 0.5601868033409119)\n",
      "(451, 0.3778465688228607)\n",
      "(452, 0.6257855296134949)\n",
      "(453, 0.540357232093811)\n",
      "(454, 0.37139376997947693)\n",
      "(455, 0.5905170440673828)\n",
      "(456, 0.2475510537624359)\n",
      "(457, 0.5879064202308655)\n",
      "(458, 0.10585180670022964)\n",
      "(459, 0.6165826320648193)\n",
      "(460, 0.05395698919892311)\n",
      "(461, 0.38873976469039917)\n",
      "(462, 0.054509684443473816)\n",
      "(463, 0.04944958910346031)\n",
      "(464, 0.04147042706608772)\n",
      "(465, 0.30639946460723877)\n",
      "(466, 0.27553218603134155)\n",
      "(467, 0.24078088998794556)\n",
      "(468, 0.7003970742225647)\n",
      "(469, 0.18941868841648102)\n",
      "(470, 0.6271247267723083)\n",
      "(471, 0.5942307710647583)\n",
      "(472, 0.14515702426433563)\n",
      "(473, 0.1562049388885498)\n",
      "(474, 0.5424187779426575)\n",
      "(475, 0.16309480369091034)\n",
      "(476, 0.16444101929664612)\n",
      "(477, 0.7142959833145142)\n",
      "(478, 0.40664806962013245)\n",
      "(479, 0.09743005782365799)\n",
      "(480, 0.17960241436958313)\n",
      "(481, 0.18457235395908356)\n",
      "(482, 0.16588331758975983)\n",
      "(483, 0.4190365672111511)\n",
      "(484, 0.7002812027931213)\n",
      "(485, 0.15680773556232452)\n",
      "(486, 0.3631182909011841)\n",
      "(487, 0.7351440191268921)\n",
      "(488, 0.14157886803150177)\n",
      "(489, 0.14615626633167267)\n",
      "(490, 0.07587039470672607)\n",
      "(491, 0.842317521572113)\n",
      "(492, 0.14752048254013062)\n",
      "(493, 0.15619385242462158)\n",
      "(494, 0.604519784450531)\n",
      "(495, 0.5120909214019775)\n",
      "(496, 0.4673328995704651)\n",
      "(497, 0.4706588685512543)\n",
      "(498, 0.4577539265155792)\n",
      "(499, 0.5459312200546265)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
